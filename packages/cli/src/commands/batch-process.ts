import { Command, Option } from 'commander';
import fs from 'fs';
import path from 'path';
import axios from 'axios';
import { listMonthFiles, type S3FileInfo } from '../aws/month-lister.js';
import { downloadFile } from '../aws/downloader.js';
import { processMecaFile } from '../utils/meca-processor.js';

interface BatchOptions {
  month: string;
  limit: number;
  apiUrl: string;
  apiKey?: string;
  output: string;
  dryRun: boolean;
  force: boolean;
  keep: boolean;
  awsBucket: string;
  awsRegion: string;
}

export const batchProcessCommand = new Command('batch-process')
  .description(
    'Batch process MECA files for a given month. Use --keep to preserve downloaded files.',
  )
  .option('-m, --month <month>', 'Month to process (YYYY-MM format)', '2025-01')
  .option('-l, --limit <number>', 'Maximum number of files to process', '10')
  .option('-a, --api-url <url>', 'API base URL', 'https://biorxiv.curvenote.dev')
  .addOption(
    new Option(
      '-k, --api-key <key>',
      'API key for authentication (or use BIORXIV_API_KEY env var)',
    ).env('BIORXIV_API_KEY'),
  )
  .option('-o, --output <dir>', 'Output directory for extracted files', './batch-extracted')
  .option('--dry-run', 'List files without processing them', false)
  .option('--force', 'Force reprocessing of existing files', false)
  .option('--keep', 'Keep MECA files after processing (default: false)', false)
  .option('--aws-bucket <bucket>', 'AWS S3 bucket name', 'biorxiv-src-monthly')
  .option('--aws-region <region>', 'AWS region', 'us-east-1')
  .action(async (options: BatchOptions) => {
    if (!options.apiKey) {
      console.error(
        '‚ùå API key is required. Please provide a valid API key using --api-key or set the BIORXIV_API_KEY environment variable.',
      );
      process.exit(1);
    }
    const response = await axios.get(`${options.apiUrl}/health`).catch((error) => {
      console.error('‚ùå API is not healthy. Please check the API URL and API key.');
      process.exit(1);
    });
    if (response.status !== 200) {
      console.error('‚ùå API is not healthy. Please check the API URL and API key.');
      process.exit(1);
    }
    try {
      console.log(`üöÄ Starting batch processing for month: ${options.month}`);
      console.log(`üìä Processing limit: ${options.limit} files`);
      console.log(`üîç Dry run mode: ${options.dryRun ? 'enabled' : 'disabled'}`);

      // Create output directory
      if (!fs.existsSync(options.output)) {
        fs.mkdirSync(options.output, { recursive: true });
      }

      // Step 1: List available MECA files for the month
      const availableFiles = await listAvailableFiles(options.month, options.limit, options);
      console.log(`üìã Found ${availableFiles.length} available files`);

      if (availableFiles.length === 0) {
        console.log('‚ùå No files found for the specified month');
        return;
      }

      // Step 2: Check which files are already processed
      const processingStatus = await checkProcessingStatus(availableFiles, options.apiUrl);

      const filesToProcess = options.force
        ? availableFiles
        : availableFiles.filter((file) => !processingStatus[file.s3Key]?.exists);

      console.log(`üìä Files to process: ${filesToProcess.length}`);
      console.log(`‚úÖ Already processed: ${availableFiles.length - filesToProcess.length}`);

      if (options.dryRun) {
        console.log('\nüìã Files that would be processed:');
        filesToProcess.forEach((file) => {
          console.log(
            `  - ${file.s3Key} (${formatFileSize(file.fileSize)}, ${file.lastModified.toLocaleDateString()})`,
          );
        });
        return;
      }

      // Step 3: Process files
      let processedCount = 0;
      let errorCount = 0;

      for (const file of filesToProcess) {
        try {
          console.log(`\nüîÑ Processing ${file.s3Key}...`);

          // Download the MECA file first
          console.log(`  üì• Downloading ${file.s3Key} from S3...`);
          await downloadFile(file.s3Key, {
            output: options.output,
          });

          // Get the local file path
          const localFilePath = path.join(options.output, path.basename(file.s3Key));
          console.log(`  üíæ Downloaded to: ${localFilePath}`);

          // Get API key from command line or environment variable
          const apiKey = options.apiKey || process.env.BIORXIV_API_KEY;

          // Process the MECA file using the utility function
          const result = await processMecaFile(localFilePath, {
            batch: file.batch,
            server: 'biorxiv',
            apiUrl: options.apiUrl,
            output: options.output,
            s3Key: file.s3Key, // Pass the full S3 key for database storage
            apiKey,
          });

          if (result.success) {
            console.log(`‚úÖ Successfully processed: ${file.s3Key}`);
            processedCount++;
          } else {
            console.log(`‚ùå Failed to process: ${file.s3Key} - ${result.error}`);
            errorCount++;
          }

          // Clean up downloaded MECA file unless --keep flag is set
          if (!options.keep) {
            try {
              // Remove the downloaded MECA file
              if (fs.existsSync(localFilePath)) {
                fs.unlinkSync(localFilePath);
                console.log(`  üßπ Cleaned up MECA file: ${path.basename(file.s3Key)}`);
              }

              // Also clean up any extracted content directory
              const extractedDir = localFilePath.replace('.meca', '');
              if (fs.existsSync(extractedDir)) {
                fs.rmSync(extractedDir, { recursive: true, force: true });
                console.log(`  üßπ Cleaned up extracted content: ${path.basename(extractedDir)}`);
              }
            } catch (cleanupError) {
              console.warn(
                `  ‚ö†Ô∏è  Warning: Could not clean up files for ${file.s3Key}:`,
                cleanupError,
              );
            }
          } else {
            console.log(`  üíæ Keeping MECA file: ${path.basename(file.s3Key)}`);
          }
        } catch (error) {
          console.error(`‚ùå Error processing ${file.s3Key}:`, error);
          errorCount++;
        }

        // Check if we've reached the limit
        if (processedCount >= options.limit) {
          console.log(`\nüõë Reached processing limit of ${options.limit} files`);
          break;
        }
      }

      // Summary
      console.log(`\nüéâ Batch processing completed!`);
      console.log(`üìä Total files: ${availableFiles.length}`);
      console.log(`‚úÖ Successfully processed: ${processedCount}`);
      if (errorCount > 0) {
        console.log(`‚ùå Errors: ${errorCount}`);
      }
      console.log(
        `‚è≠Ô∏è  Skipped (already processed): ${availableFiles.length - filesToProcess.length}`,
      );

      // Cleanup summary
      if (!options.keep) {
        console.log(`üßπ Cleanup: MECA files and extracted content removed`);
      } else {
        console.log(`üíæ Cleanup: MECA files and extracted content preserved`);
      }
    } catch (error) {
      console.error('‚ùå Error in batch processing:', error);
      process.exit(1);
    }
  });

async function listAvailableFiles(
  month: string,
  limit: number,
  options: BatchOptions,
): Promise<S3FileInfo[]> {
  return listMonthFiles({
    month,
    limit,
    awsBucket: options.awsBucket,
    awsRegion: options.awsRegion,
  });
}

async function checkProcessingStatus(
  files: S3FileInfo[],
  apiUrl: string,
): Promise<Record<string, { exists: boolean; paper?: any }>> {
  const status: Record<string, { exists: boolean; paper?: any }> = {};

  console.log('üîç Checking processing status...');

  for (const file of files) {
    try {
      const response = await axios.get(`${apiUrl}/v1/bucket?key=${encodeURIComponent(file.s3Key)}`);
      status[file.s3Key] = { exists: true, paper: response.data };
    } catch (error) {
      if (axios.isAxiosError(error) && error.response?.status === 404) {
        status[file.s3Key] = { exists: false };
      } else {
        console.warn(`‚ö†Ô∏è  Could not check status for ${file.s3Key}`);
        status[file.s3Key] = { exists: false };
      }
    }
  }

  return status;
}

function formatFileSize(bytes: number): string {
  if (bytes === 0) return '0 B';

  const k = 1024;
  const sizes = ['B', 'KB', 'MB', 'GB', 'TB'];
  const i = Math.floor(Math.log(bytes) / Math.log(k));

  return parseFloat((bytes / Math.pow(k, i)).toFixed(2)) + ' ' + sizes[i];
}
